{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e1b5f93-8b14-4bd9-9ee2-f3fda99e8a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5685ab7f-5fbc-46f5-9d90-28e8f1ce4262",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\ASUS\\Documents\\Dataset ML\\fr_dataset_stemmed.xlsx\"\n",
    "df = pd.read_excel(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c950926-97aa-47e8-bdee-36e71ed28349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Awal:\n",
      "             category  rating label  \\\n",
      "0  Home_and_Kitchen_5       5    CG   \n",
      "1  Home_and_Kitchen_5       5    CG   \n",
      "2  Home_and_Kitchen_5       5    CG   \n",
      "3  Home_and_Kitchen_5       1    CG   \n",
      "4  Home_and_Kitchen_5       5    CG   \n",
      "\n",
      "                                                text  \\\n",
      "0  Love this!  Well made, sturdy, and very comfor...   \n",
      "1  love it, a great upgrade from the original.  I...   \n",
      "2  This pillow saved my back. I love the look and...   \n",
      "3  Missing information on how to use it, but it i...   \n",
      "4  Very nice set. Good quality. We have had the s...   \n",
      "\n",
      "                                          clean_text  \\\n",
      "0  Love this  Well made sturdy and very comfortab...   \n",
      "1  love it a great upgrade from the original  Ive...   \n",
      "2  This pillow saved my back I love the look and ...   \n",
      "3  Missing information on how to use it but it is...   \n",
      "4  Very nice set Good quality We have had the set...   \n",
      "\n",
      "                                    clean_text_lower  \\\n",
      "0  love this  well made sturdy and very comfortab...   \n",
      "1  love it a great upgrade from the original  ive...   \n",
      "2  this pillow saved my back i love the look and ...   \n",
      "3  missing information on how to use it but it is...   \n",
      "4  very nice set good quality we have had the set...   \n",
      "\n",
      "                                              tokens  \\\n",
      "0  ['love', 'this', 'well', 'made', 'sturdy', 'an...   \n",
      "1  ['love', 'it', 'a', 'great', 'upgrade', 'from'...   \n",
      "2  ['this', 'pillow', 'saved', 'my', 'back', 'i',...   \n",
      "3  ['missing', 'information', 'on', 'how', 'to', ...   \n",
      "4  ['very', 'nice', 'set', 'good', 'quality', 'we...   \n",
      "\n",
      "                                    stopword_removal  \\\n",
      "0  ['love', 'well', 'made', 'sturdy', 'very', 'co...   \n",
      "1  ['love', 'great', 'upgrade', 'original', 'ive'...   \n",
      "2  ['pillow', 'saved', 'back', 'love', 'look', 'f...   \n",
      "3  ['missing', 'information', 'use', 'but', 'grea...   \n",
      "4  ['very', 'nice', 'set', 'good', 'quality', 'se...   \n",
      "\n",
      "                                            stemming  \n",
      "0  love well made sturdi veri comfort love itveri...  \n",
      "1            love great upgrad origin ive coupl year  \n",
      "2             pillow save back love look feel pillow  \n",
      "3            miss inform use but great product price  \n",
      "4   veri nice set good qualiti set two month now not  \n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Awal:\")\n",
    "print(df.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17f97731-e486-4ea6-82dc-4f9048c961d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Bag of Words telah dibuat.\n",
      "Ukuran sparse matrix (dokumen, kata unik): (40432, 37430)\n",
      "\n",
      "Contoh 20 kata pertama dari kosakata (fitur):\n",
      "['00' '000' '0005' '00199' '00200' '0036in' '0061849278' '007' '009'\n",
      " '00believ' '01' '010' '01192015' '013014' '01302016' '014' '016'\n",
      " '0182196' '01oz' '02']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df['stemming'].astype(str)\n",
    "vectorizer = CountVectorizer()\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "\n",
    "print(\"Model Bag of Words telah dibuat.\")\n",
    "print(\"Ukuran sparse matrix (dokumen, kata unik):\", X_vec.shape)\n",
    "\n",
    "print(\"\\nContoh 20 kata pertama dari kosakata (fitur):\")\n",
    "print(vectorizer.get_feature_names_out()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6a07643-958e-46ce-9293-b0d73a241d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memisahkan data menjadi 80% data latih dan 20% data uji...\n",
      "Jumlah data latih: 32345\n",
      "Jumlah data uji: 8087\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "print(\"Memisahkan data menjadi 80% data latih dan 20% data uji...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vec, \n",
    "    y, \n",
    "    test_size=0.2,    \n",
    "    random_state=42   \n",
    ")\n",
    "\n",
    "print(f\"Jumlah data latih: {X_train.shape[0]}\")\n",
    "print(f\"Jumlah data uji: {X_test.shape[0]}\")\n",
    "print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23aaf145-5cce-463e-91f8-c12b10e56da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melatih model Multinomial Naive Bayes...\n",
      "Model selesai dilatih.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Melatih model Multinomial Naive Bayes...\")\n",
    "model = MultinomialNB()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model selesai dilatih.\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b545c88-45d2-476a-87ac-500e0644e443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mengevaluasi performa model...\n",
      "\n",
      "--- HASIL AKURASI ---\n",
      "Akurasi pada Data Uji (Test Set):   83.45%\n",
      "Akurasi pada Data Latih (Train Set): 86.33%\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Mengevaluasi performa model...\")\n",
    "accuracy_test = model.score(X_test, y_test)\n",
    "accuracy_train = model.score(X_train, y_train)\n",
    "\n",
    "print(\"\\n--- HASIL AKURASI ---\")\n",
    "print(f\"Akurasi pada Data Uji (Test Set):   {accuracy_test:.2%}\")\n",
    "print(f\"Akurasi pada Data Latih (Train Set): {accuracy_train:.2%}\")\n",
    "print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0cf32f-bdb2-4bf3-b289-103f5bd521be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
