{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31df2f5-2707-47d3-9128-ac4a136155c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3415fa51-1f26-41f0-af6f-7bee656edf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\ASUS\\fr_dataset_stemmed.xlsx\"\n",
    "df = pd.read_excel(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67832076-2ee2-44aa-b365-53bb29909ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Awal:\n",
      "             category  rating label  \\\n",
      "0  Home_and_Kitchen_5       5    CG   \n",
      "1  Home_and_Kitchen_5       5    CG   \n",
      "2  Home_and_Kitchen_5       5    CG   \n",
      "3  Home_and_Kitchen_5       1    CG   \n",
      "4  Home_and_Kitchen_5       5    CG   \n",
      "\n",
      "                                                text  \\\n",
      "0  Love this!  Well made, sturdy, and very comfor...   \n",
      "1  love it, a great upgrade from the original.  I...   \n",
      "2  This pillow saved my back. I love the look and...   \n",
      "3  Missing information on how to use it, but it i...   \n",
      "4  Very nice set. Good quality. We have had the s...   \n",
      "\n",
      "                                          clean_text  \\\n",
      "0  Love this  Well made sturdy and very comfortab...   \n",
      "1  love it a great upgrade from the original  Ive...   \n",
      "2  This pillow saved my back I love the look and ...   \n",
      "3  Missing information on how to use it but it is...   \n",
      "4  Very nice set Good quality We have had the set...   \n",
      "\n",
      "                                    clean_text_lower  \\\n",
      "0  love this  well made sturdy and very comfortab...   \n",
      "1  love it a great upgrade from the original  ive...   \n",
      "2  this pillow saved my back i love the look and ...   \n",
      "3  missing information on how to use it but it is...   \n",
      "4  very nice set good quality we have had the set...   \n",
      "\n",
      "                                              tokens  \\\n",
      "0  ['love', 'this', 'well', 'made', 'sturdy', 'an...   \n",
      "1  ['love', 'it', 'a', 'great', 'upgrade', 'from'...   \n",
      "2  ['this', 'pillow', 'saved', 'my', 'back', 'i',...   \n",
      "3  ['missing', 'information', 'on', 'how', 'to', ...   \n",
      "4  ['very', 'nice', 'set', 'good', 'quality', 'we...   \n",
      "\n",
      "                                    stopword_removal  \\\n",
      "0  ['love', 'well', 'made', 'sturdy', 'very', 'co...   \n",
      "1  ['love', 'great', 'upgrade', 'original', 'ive'...   \n",
      "2  ['pillow', 'saved', 'back', 'love', 'look', 'f...   \n",
      "3  ['missing', 'information', 'use', 'but', 'grea...   \n",
      "4  ['very', 'nice', 'set', 'good', 'quality', 'se...   \n",
      "\n",
      "                                            stemming  \n",
      "0  love well made sturdi veri comfort love itveri...  \n",
      "1            love great upgrad origin ive coupl year  \n",
      "2             pillow save back love look feel pillow  \n",
      "3            miss inform use but great product price  \n",
      "4   veri nice set good qualiti set two month now not  \n"
     ]
    }
   ],
   "source": [
    "print(\"Data Awal:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9238f477-db61-41c7-a5e0-ca627d07f18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membuat fitur menggunakan TF-IDF Vectorizer dengan N-gram (1, 2)...\n",
      "Ukuran matriks fitur: (40432, 599402)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import pandas as pd\n",
    "\n",
    "print(\"Membuat fitur menggunakan TF-IDF Vectorizer dengan N-gram (1, 2)...\")\n",
    "X_text = df['stemming'].astype(str)\n",
    "y = df['label']\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2)) \n",
    "X_vec = vectorizer.fit_transform(X_text)\n",
    "\n",
    "print(\"Ukuran matriks fitur:\", X_vec.shape)\n",
    "print(\"-\" * 40)\n",
    "\n",
    "features = vectorizer.get_feature_names_out()\n",
    "idf = vectorizer.idf_\n",
    "\n",
    "rows = []\n",
    "for i in range(X_vec.shape[0]):\n",
    "    row_data = {}\n",
    "    ngrams_used = []\n",
    "    for idx in X_vec[i].indices:\n",
    "        word = features[idx]\n",
    "        tfidf_val = X_vec[i, idx]\n",
    "        idf_val = idf[idx]\n",
    "        tf_val = tfidf_val / idf_val\n",
    "        row_data[word] = {\"TF\": tf_val, \"IDF\": idf_val, \"TFIDF\": tfidf_val}\n",
    "        ngrams_used.append(word)\n",
    "    rows.append((row_data, ngrams_used))\n",
    "\n",
    "df_out = df.copy()\n",
    "df_out[\"TF\"] = [str({w: v[\"TF\"] for w,v in r[0].items()}) for r in rows]\n",
    "df_out[\"IDF\"] = [str({w: v[\"IDF\"] for w,v in r[0].items()}) for r in rows]\n",
    "df_out[\"TFIDF\"] = [str({w: v[\"TFIDF\"] for w,v in r[0].items()}) for r in rows]\n",
    "df_out[\"NGRAM\"] = [\", \".join(r[1]) for r in rows]\n",
    "\n",
    "output_path = \"hasil_tfidf_ngram.xlsx\"\n",
    "df_out.to_excel(output_path, sheet_name=\"fr_tfidf_ngram\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b3623-ff03-4d67-b317-3b6a21895cec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
