{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1fcd701-d648-4d55-a1ae-a4c82e625b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bf774a3-1861-4b33-92b5-7ae5b82f0e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\ASUS\\Documents\\Dataset ML\\fr_dataset_stemmed.xlsx\"\n",
    "df = pd.read_excel(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4db8619a-70a3-4114-aabf-93f33748b962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Awal:\n",
      "             category  rating label  \\\n",
      "0  Home_and_Kitchen_5       5    CG   \n",
      "1  Home_and_Kitchen_5       5    CG   \n",
      "2  Home_and_Kitchen_5       5    CG   \n",
      "3  Home_and_Kitchen_5       1    CG   \n",
      "4  Home_and_Kitchen_5       5    CG   \n",
      "\n",
      "                                                text  \\\n",
      "0  Love this!  Well made, sturdy, and very comfor...   \n",
      "1  love it, a great upgrade from the original.  I...   \n",
      "2  This pillow saved my back. I love the look and...   \n",
      "3  Missing information on how to use it, but it i...   \n",
      "4  Very nice set. Good quality. We have had the s...   \n",
      "\n",
      "                                          clean_text  \\\n",
      "0  Love this  Well made sturdy and very comfortab...   \n",
      "1  love it a great upgrade from the original  Ive...   \n",
      "2  This pillow saved my back I love the look and ...   \n",
      "3  Missing information on how to use it but it is...   \n",
      "4  Very nice set Good quality We have had the set...   \n",
      "\n",
      "                                    clean_text_lower  \\\n",
      "0  love this  well made sturdy and very comfortab...   \n",
      "1  love it a great upgrade from the original  ive...   \n",
      "2  this pillow saved my back i love the look and ...   \n",
      "3  missing information on how to use it but it is...   \n",
      "4  very nice set good quality we have had the set...   \n",
      "\n",
      "                                              tokens  \\\n",
      "0  ['love', 'this', 'well', 'made', 'sturdy', 'an...   \n",
      "1  ['love', 'it', 'a', 'great', 'upgrade', 'from'...   \n",
      "2  ['this', 'pillow', 'saved', 'my', 'back', 'i',...   \n",
      "3  ['missing', 'information', 'on', 'how', 'to', ...   \n",
      "4  ['very', 'nice', 'set', 'good', 'quality', 'we...   \n",
      "\n",
      "                                    stopword_removal  \\\n",
      "0  ['love', 'well', 'made', 'sturdy', 'very', 'co...   \n",
      "1  ['love', 'great', 'upgrade', 'original', 'ive'...   \n",
      "2  ['pillow', 'saved', 'back', 'love', 'look', 'f...   \n",
      "3  ['missing', 'information', 'use', 'but', 'grea...   \n",
      "4  ['very', 'nice', 'set', 'good', 'quality', 'se...   \n",
      "\n",
      "                                            stemming  \n",
      "0  love well made sturdi veri comfort love itveri...  \n",
      "1            love great upgrad origin ive coupl year  \n",
      "2             pillow save back love look feel pillow  \n",
      "3            miss inform use but great product price  \n",
      "4   veri nice set good qualiti set two month now not  \n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Awal:\")\n",
    "print(df.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "302135bb-1a2d-40c4-bea7-d9c4771b4f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membuat fitur menggunakan TF-IDF Vectorizer dengan N-gram (1, 2)...\n",
      "Ukuran matriks fitur: (40432, 599402)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "print(\"Membuat fitur menggunakan TF-IDF Vectorizer dengan N-gram (1, 2)...\")\n",
    "X_text = df['stemming'].astype(str)\n",
    "y = df['label']\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2)) \n",
    "X_vec = vectorizer.fit_transform(X_text)\n",
    "\n",
    "print(\"Ukuran matriks fitur:\", X_vec.shape)\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0f6f1cd-6579-4b15-bbd4-1bc73a20d80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memisahkan data menjadi 80% data latih dan 20% data uji...\n",
      "Jumlah data latih: 32345\n",
      "Jumlah data uji: 8087\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Memisahkan data menjadi 80% data latih dan 20% data uji...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vec, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Jumlah data latih: {X_train.shape[0]}\")\n",
    "print(f\"Jumlah data uji: {X_test.shape[0]}\")\n",
    "print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdb7465c-5e5f-4c22-9852-895fa23cf2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melatih model Multinomial Naive Bayes...\n",
      "Model Naive Bayes selesai dilatih.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "print(\"Melatih model Multinomial Naive Bayes...\")\n",
    "\n",
    "model = MultinomialNB()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model Naive Bayes selesai dilatih.\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e01b9b-7d05-48ed-bece-88281f388ef9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test_text)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   -> Prediksi selesai dibuat.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m2. Menghitung dan menampilkan hasil evaluasi akhir...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_pred = best_model.predict(X_test_text)\n",
    "print(\"   -> Prediksi selesai dibuat.\")\n",
    "\n",
    "\n",
    "print(\"\\n2. Menghitung dan menampilkan hasil evaluasi akhir...\")\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"   -> ðŸ“Š F1-Score (Weighted) pada Test Set: {f1:.4f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"   -> âœ… Akurasi pada Test Set: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Laporan Klasifikasi Lengkap untuk Model Terbaik ---\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"\\n3. Membuat visualisasi Confusion Matrix untuk Model Terbaik...\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=best_model.classes_, \n",
    "            yticklabels=best_model.classes_)\n",
    "plt.xlabel('Label Prediksi')\n",
    "plt.ylabel('Label Sebenarnya')\n",
    "plt.title('Confusion Matrix untuk Model Naive Bayes (Hasil Tuning)')\n",
    "plt.show()\n",
    "print(\"   -> Selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d16bc-792f-488c-b73d-2d9d55987670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
